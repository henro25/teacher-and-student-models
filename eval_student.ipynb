{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/henro25/teacher-and-student-models.git\n",
    "!mv /content/teacher-and-student-models/* /content\n",
    "!rm -r /content/teacher-and-student-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%pip install fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from transformers import AdamW\n",
    "from torchvision.models import resnet18\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "class Config:\n",
    "    in_channels = 3\n",
    "    num_classes = 10\n",
    "    batch_size = 64\n",
    "    lr = 1e-3\n",
    "    epochs = 20\n",
    "    num_students = 3\n",
    "    num_big_classes = num_students\n",
    "    hidden_dim = 256\n",
    "    #temperature = 3.0\n",
    "    temperature = 5.0\n",
    "    alpha = 0.7\n",
    "    teacher_model_path = \"resnet18_cifar10_tailored_epoch20.pth\"\n",
    "    student_model_path = \"student_{}.pth\"\n",
    "\n",
    "config = Config()\n",
    "\n",
    "class ResNet18CIFAR10(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet18CIFAR10, self).__init__()\n",
    "        self.model = resnet18(pretrained=False)  # Load base ResNet-18\n",
    "        self.model.conv1 = nn.Conv2d(\n",
    "            in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False\n",
    "        )  # Replace first conv layer\n",
    "        self.model.maxpool = nn.Identity()  # Remove MaxPooling layer\n",
    "        self.model.fc = nn.Linear(512, num_classes)  # Adjust fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# Data Loaders with Data Augmentation\n",
    "def get_data_loaders():\n",
    "    # Training transformations (with augmentations)\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))  # Mean and std of CIFAR-10\n",
    "    ])\n",
    "\n",
    "    # Test transformations (without augmentations)\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))  # Same mean and std as training set\n",
    "    ])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform_train, download=True)\n",
    "    test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform_test, download=True)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    return train_loader, test_loader\n",
    "\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8 * 8 * 64, config.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(config.hidden_dim, config.num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "    \n",
    "\n",
    "def evaluate_with_metrics(model, loader, device, description=\"Model\"):\n",
    "    model.eval()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    total_loss, correct = 0, 0\n",
    "    total_samples = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            batch_size = inputs.size(0)\n",
    "\n",
    "            if i == 0:\n",
    "                start_time = time.time()\n",
    "\n",
    "                flops_input = inputs[:1].to(device)\n",
    "                flops_analysis = FlopCountAnalysis(model, flops_input)\n",
    "                flops_per_image = flops_analysis.total() / batch_size\n",
    "\n",
    "                end_time = time.time()\n",
    "\n",
    "                latency = (end_time - start_time) / batch_size\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            correct += (outputs.argmax(1) == targets).sum().item()\n",
    "            total_samples += batch_size\n",
    "\n",
    "    accuracy = correct / total_samples\n",
    "    print(f\"{description} Results:\")\n",
    "    print(f\"Loss: {total_loss / len(loader):.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Latency per Image: {latency:.6f} secs\")\n",
    "    print(f\"FLOPs per Image: {flops_per_image / 1e6:.2f} MFLOPs\")\n",
    "\n",
    "    return total_loss, accuracy, latency, flops_per_image\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    train_loader, test_loader = get_data_loaders()\n",
    "    \n",
    "    student_model_folder = \"student_models\"\n",
    "    student_model_paths = [\n",
    "        \"student_c1_l0.0625.pth\",\n",
    "        \"student_c1_l0.125.pth\",\n",
    "        \"student_c1_l0.25.pth\",\n",
    "        \"student_c1_l0.5.pth\",\n",
    "        \"student_c1_l1.pth\",\n",
    "        \"student_c1_l2.pth\",\n",
    "        \"student_c1_l4.pth\",\n",
    "        \"student_c1_l8.pth\"\n",
    "    ]\n",
    "    \n",
    "    # For each student model, load the weights and evaluate\n",
    "    students = []\n",
    "    for i, student_model_path in enumerate(student_model_paths):\n",
    "        student = StudentModel().to(device)\n",
    "        student.load_state_dict(torch.load(f\"{student_model_folder}/{student_model_path}\"))\n",
    "        students.append(student)\n",
    "        print(f\"Student {i + 1} loaded from {student_model_path}\")\n",
    "        evaluate_with_metrics(student, test_loader, device, description=f\"Student {i + 1}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
